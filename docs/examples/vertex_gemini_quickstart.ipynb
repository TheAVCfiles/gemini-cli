{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ff5ff3c",
   "metadata": {},
   "source": [
    "\n",
    "# Vertex AI â€“ Gemini Quickstart (Colab/Notebook)\n",
    "\n",
    "This notebook shows how to use **`google-genai`** with an **API key** to call Gemini on Vertex AI.\n",
    "- Works in **Colab** or locally (Jupyter).\n",
    "- Includes **streaming** and **non-streaming** calls, JSON-structured output, and quick helpers.\n",
    "\n",
    "> **Prereqs**  \n",
    "> 1) In project `starry-argon-463819-a2`, create an **API key** with GenAI access.  \n",
    "> 2) Paste it into the cell below.  \n",
    "> 3) Ensure the model ID is available in your project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a285bb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Install the SDK\n",
    "!pip -q install --upgrade google-genai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7920ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ðŸ”‘ Set your API key here (temporary for this runtime only)\n",
    "import os\n",
    "\n",
    "GOOGLE_CLOUD_API_KEY = \"PASTE_YOUR_KEY_HERE\"  # <-- replace\n",
    "os.environ[\"GOOGLE_CLOUD_API_KEY\"] = GOOGLE_CLOUD_API_KEY\n",
    "\n",
    "PROJECT_ID = \"starry-argon-463819-a2\"\n",
    "REGION = \"us-central1\"\n",
    "\n",
    "assert os.environ.get(\"GOOGLE_CLOUD_API_KEY\") and os.environ[\"GOOGLE_CLOUD_API_KEY\"] != \"PASTE_YOUR_KEY_HERE\",     \"Please paste a real API key above.\"\n",
    "print(\"API key is set in the environment.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1b5bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ðŸ§  Client bootstrap\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import os\n",
    "\n",
    "MODEL_ID = \"gemini-2.5-flash-preview-09-2025\"  # update if needed\n",
    "\n",
    "client = genai.Client(\n",
    "    vertexai=True,  # use Vertex AI endpoint\n",
    "    api_key=os.environ[\"GOOGLE_CLOUD_API_KEY\"],\n",
    ")\n",
    "\n",
    "print(\"Client ready. Model:\", MODEL_ID)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edd5629",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Non-streaming: basic text generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2390336",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt = \"List three whimsical use cases for a white-label AI content engine.\"\n",
    "cfg = types.GenerateContentConfig(\n",
    "    temperature=0.9,\n",
    "    top_p=0.95,\n",
    "    max_output_tokens=512,\n",
    "    system_instruction=[types.Part.from_text(text=(\n",
    "        \"You are a helpful creative system that produces useful, remixable assets quickly.\"\n",
    "    ))],\n",
    ")\n",
    "\n",
    "resp = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=[types.Content(role=\"user\", parts=[types.Part.from_text(text=prompt)])],\n",
    "    config=cfg,\n",
    ")\n",
    "\n",
    "print(resp.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed408ee4",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Streaming: token-by-token output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e079cc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cfg_stream = types.GenerateContentConfig(\n",
    "    temperature=1.0,\n",
    "    top_p=0.95,\n",
    "    max_output_tokens=1024,\n",
    ")\n",
    "\n",
    "print(\"Streaming response...\")\n",
    "for chunk in client.models.generate_content_stream(\n",
    "    model=MODEL_ID,\n",
    "    contents=[types.Content(role=\"user\", parts=[types.Part.from_text(text=\"Write a one-paragraph product pitch for a modular AI demo kit.\")])],\n",
    "    config=cfg_stream,\n",
    "):\n",
    "    if chunk.text:\n",
    "        print(chunk.text, end=\"\")\n",
    "print(\"\n",
    "\n",
    "â€” end of stream â€”\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f88f837",
   "metadata": {},
   "source": [
    "\n",
    "## 3) JSON-structured output\n",
    "Ask the model to conform to a simple JSON schema for downstream use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d995ec14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "schema = {\n",
    "  \"type\": \"object\",\n",
    "  \"properties\": {\n",
    "    \"title\": {\"type\": \"string\"},\n",
    "    \"bullets\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "    \"cta\": {\"type\": \"string\"}\n",
    "  },\n",
    "  \"required\": [\"title\", \"bullets\", \"cta\"]\n",
    "}\n",
    "\n",
    "cfg_json = types.GenerateContentConfig(\n",
    "    temperature=0.8,\n",
    "    response_mime_type=\"application/json\",\n",
    "    response_schema=schema\n",
    ")\n",
    "\n",
    "resp_json = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=[types.Content(role=\"user\", parts=[types.Part.from_text(text=\"Create a landing blurb for an AI-powered slide deck generator.\")])],\n",
    "    config=cfg_json,\n",
    ")\n",
    "\n",
    "print(resp_json.text)  # should be valid JSON\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b73a27",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Safety + long outputs (use carefully)\n",
    "Preview models allow configuring safety thresholds. Here we disable most checks for fast prototyping (adjust for prod).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7028c840",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cfg_loose = types.GenerateContentConfig(\n",
    "    temperature=1.0,\n",
    "    top_p=0.95,\n",
    "    max_output_tokens=4096,\n",
    "    safety_settings=[\n",
    "        types.SafetySetting(category=\"HARM_CATEGORY_HATE_SPEECH\", threshold=\"OFF\"),\n",
    "        types.SafetySetting(category=\"HARM_CATEGORY_DANGEROUS_CONTENT\", threshold=\"OFF\"),\n",
    "        types.SafetySetting(category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\", threshold=\"OFF\"),\n",
    "        types.SafetySetting(category=\"HARM_CATEGORY_HARASSMENT\", threshold=\"OFF\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "resp_long = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=[types.Content(role=\"user\", parts=[types.Part.from_text(text=\"Draft a 6-section outline for a product launch brief aimed at enterprise buyers.\")])],\n",
    "    config=cfg_loose,\n",
    ")\n",
    "\n",
    "print(resp_long.text[:2000])  # preview first ~2k chars\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446fa911",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Pro tip: switch models quickly\n",
    "Just change `MODEL_ID` (ensure it's enabled for your project). Common choices include `gemini-2.0-flash`, `gemini-2.0-pro`, or later previews.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
