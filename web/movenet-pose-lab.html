<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>MoveNet Pose Lab</title>
    <link
      rel="preconnect"
      href="https://fonts.googleapis.com"
    />
    <link
      rel="preconnect"
      href="https://fonts.gstatic.com"
      crossorigin
    />
    <link
      href="https://fonts.googleapis.com/css2?family=Space+Grotesk:wght@400;500;600&display=swap"
      rel="stylesheet"
    />
    <style>
      :root {
        color-scheme: dark;
        font-family: "Space Grotesk", system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
        background: radial-gradient(circle at 20% -10%, #3f3cbb, #0b1026 60%);
        color: #f8f9ff;
      }

      * {
        box-sizing: border-box;
      }

      body {
        margin: 0;
        min-height: 100vh;
        display: flex;
        flex-direction: column;
        background: inherit;
      }

      header {
        padding: clamp(2.5rem, 6vw, 4rem) 1.5rem 1.5rem;
        text-align: center;
      }

      header h1 {
        margin: 0;
        font-size: clamp(2.25rem, 5vw, 3.5rem);
        letter-spacing: -0.02em;
        text-shadow: 0 18px 45px rgba(99, 102, 241, 0.35);
      }

      header p {
        max-width: 720px;
        margin: 1rem auto 0;
        color: rgba(226, 232, 255, 0.78);
        font-size: 1.05rem;
        line-height: 1.6;
      }

      main {
        flex: 1;
        width: min(1100px, 100%);
        margin: 0 auto 3rem;
        padding: 0 1.5rem 3rem;
        display: grid;
        gap: 1.5rem;
      }

      .surface {
        background: rgba(15, 23, 56, 0.86);
        border-radius: 24px;
        border: 1px solid rgba(99, 102, 241, 0.35);
        box-shadow: 0 28px 60px rgba(12, 18, 50, 0.45);
        padding: clamp(1.5rem, 3vw, 2rem);
        backdrop-filter: blur(16px);
      }

      .deck {
        display: grid;
        gap: 1.25rem;
      }

      @media (min-width: 960px) {
        main {
          grid-template-columns: 2.2fr 1fr;
          align-items: start;
        }
      }

      .stage {
        position: relative;
        aspect-ratio: 4 / 3;
        border-radius: 20px;
        overflow: hidden;
        background: rgba(10, 14, 35, 0.9);
      }

      video,
      canvas {
        position: absolute;
        inset: 0;
        width: 100%;
        height: 100%;
        object-fit: cover;
      }

      .hud {
        display: grid;
        gap: 1rem;
      }

      .hud button {
        appearance: none;
        border: 0;
        border-radius: 16px;
        padding: 0.75rem 1.2rem;
        font-weight: 600;
        letter-spacing: 0.02em;
        background: linear-gradient(120deg, #6366f1, #a855f7);
        color: #0f1023;
        cursor: pointer;
        transition: transform 0.2s ease, box-shadow 0.2s ease;
      }

      .hud button:hover {
        transform: translateY(-1px);
        box-shadow: 0 18px 38px rgba(99, 102, 241, 0.45);
      }

      .stat-grid {
        display: grid;
        gap: 0.75rem;
      }

      @media (min-width: 640px) {
        .stat-grid {
          grid-template-columns: repeat(2, minmax(0, 1fr));
        }
      }

      .stat-card {
        padding: 1rem 1.2rem;
        border-radius: 18px;
        background: rgba(24, 31, 64, 0.88);
        border: 1px solid rgba(148, 163, 255, 0.18);
        display: grid;
        gap: 0.4rem;
      }

      .stat-label {
        font-size: 0.85rem;
        letter-spacing: 0.08em;
        text-transform: uppercase;
        color: rgba(226, 232, 255, 0.6);
      }

      .stat-value {
        font-size: 1.15rem;
        font-weight: 600;
      }

      .log {
        font-size: 0.95rem;
        line-height: 1.5;
        color: rgba(226, 232, 255, 0.76);
      }

      .log strong {
        color: #f9fafc;
      }

      .error {
        border-radius: 16px;
        padding: 0.9rem 1.1rem;
        background: rgba(239, 68, 68, 0.1);
        border: 1px solid rgba(239, 68, 68, 0.35);
        color: #fee2e2;
        margin-top: 1rem;
        display: none;
      }

      .surface.error-visible .error {
        display: block;
      }
    </style>
  </head>
  <body>
    <header>
      <h1>MoveNet Pose Lab</h1>
      <p>
        Spin up your webcam, let the MoveNet Lightning model track your posture, and study the
        live pose overlay. Built with TensorFlow.js and the <code>@tensorflow-models/pose-detection</code>
        package for rapid prototyping.
      </p>
    </header>
    <main>
      <section class="surface deck">
        <div class="stage">
          <video id="video" playsinline muted></video>
          <canvas id="overlay"></canvas>
        </div>
        <div class="hud">
          <button id="toggle">Start camera</button>
          <div class="stat-grid">
            <article class="stat-card">
              <span class="stat-label">Frames per second</span>
              <span class="stat-value" id="fps">0</span>
            </article>
            <article class="stat-card">
              <span class="stat-label">Visible keypoints</span>
              <span class="stat-value" id="keypoint-count">0</span>
            </article>
          </div>
          <p class="log">
            MoveNet Lightning favors real-time feedback. Make sure you have good lighting and stand roughly
            one meter from the camera for the clearest joints. Keypoints below a confidence score of 0.3 are hidden
            to avoid jitter.
          </p>
        </div>
        <div class="error" role="alert" id="error"></div>
      </section>
      <aside class="surface">
        <h2>How it works</h2>
        <p class="log">
          The detector estimates a single body pose per frame. Each pass fetches the keypoint coordinates and draws both
          skeleton lines and joint markers onto the canvas overlay. The lightning variant is small enough for most laptops
          to run locally without a GPU. Toggle the camera to pause inference and release the media stream.
        </p>
        <p class="log">
          All inference happens entirely in the browser&mdash;no frames ever leave your device. Reload the page to reset.
          If you deny camera permissions, use the button above to try again.
        </p>
      </aside>
    </main>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.18.0/dist/tf.min.js" integrity="sha384-xw1OVnK8zOBIbduorYXM1ik6pRSwWe1L2X6AQXSE1Pj28OWRsAyPrYlQp0ap9+8K" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection@4.1.0/dist/pose-detection.min.js" integrity="sha384-ShLaKOR7um+YNliG7wHe80l+j1F0nt6bFpLJhq1DYw5dL8wg3KeM/Ja3vTQ3lSCs" crossorigin="anonymous"></script>
    <script>
      const videoEl = document.getElementById('video');
      const canvasEl = document.getElementById('overlay');
      const ctx = canvasEl.getContext('2d');
      const toggleBtn = document.getElementById('toggle');
      const fpsEl = document.getElementById('fps');
      const keypointEl = document.getElementById('keypoint-count');
      const errorEl = document.getElementById('error');
      const deck = document.querySelector('.surface.deck');

      let detector;
      let stream;
      let rafId;
      let lastFrameTime = performance.now();

      const CONNECTED_PARTS = poseDetection.util.getAdjacentPairs(
        poseDetection.SupportedModels.MoveNet
      );

      const SCORE_THRESHOLD = 0.3;

      async function ensureDetector() {
        if (!detector) {
          detector = await poseDetection.createDetector(
            poseDetection.SupportedModels.MoveNet,
            {
              modelType: poseDetection.movenet.modelType.SINGLEPOSE_LIGHTNING,
            }
          );
        }
        return detector;
      }

      function resizeCanvas() {
        const { videoWidth, videoHeight } = videoEl;
        if (!videoWidth || !videoHeight) {
          return;
        }
        canvasEl.width = videoWidth;
        canvasEl.height = videoHeight;
      }

      async function startCamera() {
        try {
          stream = await navigator.mediaDevices.getUserMedia({
            video: { facingMode: 'user', width: 640, height: 480 },
            audio: false,
          });
          videoEl.srcObject = stream;
          await videoEl.play();
          resizeCanvas();
        } catch (err) {
          handleError('Camera access denied. Please allow webcam permissions and try again.');
          throw err;
        }
      }

      function stopCamera() {
        if (rafId) {
          cancelAnimationFrame(rafId);
          rafId = undefined;
        }
        if (stream) {
          stream.getTracks().forEach((track) => track.stop());
          stream = undefined;
        }
        if (detector) {
          detector.dispose();
          detector = undefined;
        }
        videoEl.srcObject = null;
        keypointEl.textContent = '0';
        fpsEl.textContent = '0';
        ctx.clearRect(0, 0, canvasEl.width, canvasEl.height);
      }

      function handleError(message) {
        errorEl.textContent = message;
        deck.classList.add('error-visible');
      }

      function clearError() {
        errorEl.textContent = '';
        deck.classList.remove('error-visible');
      }

      function drawSkeleton(keypoints) {
        ctx.clearRect(0, 0, canvasEl.width, canvasEl.height);
        ctx.drawImage(videoEl, 0, 0, canvasEl.width, canvasEl.height);

        ctx.lineWidth = 4;
        ctx.strokeStyle = 'rgba(99, 102, 241, 0.75)';
        ctx.fillStyle = '#38fbd6';

        for (const [i, j] of CONNECTED_PARTS) {
          const kp1 = keypoints[i];
          const kp2 = keypoints[j];
          if (kp1.score > SCORE_THRESHOLD && kp2.score > SCORE_THRESHOLD) {
            ctx.beginPath();
            ctx.moveTo(kp1.x, kp1.y);
            ctx.lineTo(kp2.x, kp2.y);
            ctx.stroke();
          }
        }

        keypoints.forEach((kp) => {
          if (kp.score > SCORE_THRESHOLD) {
            ctx.beginPath();
            ctx.arc(kp.x, kp.y, 6, 0, Math.PI * 2);
            ctx.fill();
          }
        });
      }

      async function renderFrame() {
        const detectorInstance = await ensureDetector();
        const poses = await detectorInstance.estimatePoses(videoEl, {
          maxPoses: 1,
          flipHorizontal: true,
        });

        const pose = poses[0];
        const keypoints = pose?.keypoints ?? [];
        const visibleKeypoints = keypoints.filter((kp) => kp.score > SCORE_THRESHOLD);
        keypointEl.textContent = String(visibleKeypoints.length);

        drawSkeleton(keypoints);

        const now = performance.now();
        const delta = now - lastFrameTime;
        lastFrameTime = now;
        if (delta > 0) {
          fpsEl.textContent = (1000 / delta).toFixed(1);
        }

        rafId = requestAnimationFrame(renderFrame);
      }

      async function toggleCamera() {
        clearError();
        if (stream) {
          stopCamera();
          toggleBtn.textContent = 'Start camera';
          return;
        }

        if (!navigator.mediaDevices?.getUserMedia) {
          handleError('Your browser does not support webcam access. Try Chrome, Edge, or Firefox.');
          return;
        }

        try {
          await startCamera();
          await ensureDetector();
          lastFrameTime = performance.now();
          toggleBtn.textContent = 'Stop camera';
          rafId = requestAnimationFrame(renderFrame);
        } catch (err) {
          stopCamera();
        }
      }

      toggleBtn.addEventListener('click', toggleCamera);

      window.addEventListener('beforeunload', () => {
        stopCamera();
      });

      window.addEventListener('resize', () => {
        resizeCanvas();
      });

      videoEl.addEventListener('loadedmetadata', resizeCanvas);
    </script>
  </body>
</html>
