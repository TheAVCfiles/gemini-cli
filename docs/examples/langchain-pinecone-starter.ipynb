{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain + Pinecone Starter Pipeline\n",
    "\n",
    "This notebook ingests a handful of local documents, indexes them in Pinecone, and runs a retrieval-augmented generation (RAG) query using OpenAI models.\n",
    "\n",
    "**Prerequisites**\n",
    "\n",
    "* Python 3.10+ environment with Jupyter.\n",
    "* API keys exported as environment variables:\n",
    "  * `OPENAI_API_KEY` (for both text embeddings and chat completions).\n",
    "  * `PINECONE_API_KEY` and `PINECONE_ENVIRONMENT`.\n",
    "* A Pinecone index with cosine similarity and an embedding dimension that matches the embedding model (e.g. `text-embedding-3-large` \u2192 3072).\n",
    "\n",
    "If you already have an OpenAI-hosted vector store (for example: [`vs_6859e43920848191a894dd36ecf0595a`](https://platform.openai.com/storage/vector_stores/vs_6859e43920848191a894dd36ecf0595a)), you can skip the Pinecone indexing cells and adapt the retrieval logic accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install --upgrade langchain langchain-openai pinecone-client tiktoken unstructured\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "Set the runtime configuration and sanity-check the required environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "# Fail fast if critical environment variables are missing.\n",
    "required_env = [\"OPENAI_API_KEY\", \"PINECONE_API_KEY\", \"PINECONE_ENVIRONMENT\"]\n",
    "missing = [var for var in required_env if not os.environ.get(var)]\n",
    "if missing:\n",
    "    raise EnvironmentError(f\"Missing environment variables: {missing}\")\n",
    "\n",
    "EMBED_MODEL = \"text-embedding-3-large\"\n",
    "CHAT_MODEL = \"gpt-4o-mini\"\n",
    "INDEX_NAME = \"roque-ingest\"  # change to your Pinecone index\n",
    "NAMESPACE = \"demo\"\n",
    "METADATA_SOURCE = \"notebook-demo\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create sample documents\n",
    "Replace these with your own IP ingestion flow. In production you would pull from cloud storage, OCR PDFs, transcribe audio, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_texts = [\n",
    "    (\"balanchine-cipher.txt\", \"Balanchine Cipher\", \"A short excerpt describing the Balanchine ritual blueprint and its choreography-driven mnemonic devices.\"),\n",
    "    (\"rosetta-console.txt\", \"Rosetta Console\", \"Notes on console interactions, fail-safes, and curator touchpoints for the ROQUE activation sequence.\"),\n",
    "    (\"market-scan.txt\", \"Market Scan\", \"A synthetic daily scan capturing volatility, hype spikes, and the Newton gas fee index across social networks.\"),\n",
    "]\n",
    "\n",
    "documents = []\n",
    "for filename, title, summary in seed_texts:\n",
    "    text = f\"# {title}\\n\\n{summary}\\n\\nTimestamp: {datetime.utcnow().isoformat()}Z\\n\"\n",
    "    documents.append(Document(page_content=text, metadata={\"source\": METADATA_SOURCE, \"title\": title, \"filename\": filename}))\n",
    "\n",
    "print(f\"Created {len(documents)} in-memory documents.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Chunk and embed\n",
    "Chunk documents with provenance metadata and generate embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=120)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "print(f\"Split into {len(chunks)} chunks.\")\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=EMBED_MODEL)\n",
    "embedding_vectors = embeddings.embed_documents([chunk.page_content for chunk in chunks])\n",
    "print(f\"Embedded {len(embedding_vectors)} chunks.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Upsert into Pinecone\n",
    "Create (or connect to) an index and upsert the chunk embeddings with metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "\n",
    "pc = Pinecone(api_key=os.environ[\"PINECONE_API_KEY\"])\n",
    "if INDEX_NAME not in [index_info.name for index_info in pc.list_indexes()]:\n",
    "    pc.create_index(\n",
    "        name=INDEX_NAME,\n",
    "        dimension=len(embedding_vectors[0]),\n",
    "        metric=\"cosine\",\n",
    "        spec={\"serverless\": {\"cloud\": \"aws\", \"region\": os.environ[\"PINECONE_ENVIRONMENT\"]}}\n",
    "    )\n",
    "index = pc.Index(INDEX_NAME)\n",
    "\n",
    "vectors = []\n",
    "for i, (chunk, vector) in enumerate(zip(chunks, embedding_vectors)):\n",
    "    metadata = chunk.metadata | {\"chunk_id\": i, \"ingested_at\": datetime.utcnow().isoformat() + \"Z\"}\n",
    "    vectors.append({\"id\": f\"{chunk.metadata.get('filename', 'doc')}-{i}\", \"values\": vector, \"metadata\": metadata})\n",
    "\n",
    "index.upsert(vectors=vectors, namespace=NAMESPACE)\n",
    "print(f\"Upserted {len(vectors)} vectors into namespace '{NAMESPACE}'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build a LangChain retriever and QA chain\n",
    "Use the vector store to retrieve context and stream it into a ChatOpenAI model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Pinecone as PineconeVectorStore\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "vectorstore = PineconeVectorStore(\n",
    "    index=index,\n",
    "    embedding=embeddings,\n",
    "    text_key=\"page_content\",\n",
    "    namespace=NAMESPACE\n",
    ")\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
    "llm = ChatOpenAI(model=CHAT_MODEL, temperature=0.2)\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "query = \"How do we validate a ROQUE artifact before anchoring it?\"\n",
    "result = qa_chain.invoke({\"query\": query})\n",
    "print(result[\"result\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Inspect provenance\n",
    "Each returned document still has the metadata we attached earlier, enabling full provenance tracking.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in result['source_documents']:\n",
    "    print(f\"--- {doc.metadata['title']} ({doc.metadata['filename']}) ---\")\n",
    "    print(doc.page_content[:300] + '...')\n",
    "    print(doc.metadata)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "* Swap the in-memory `seed_texts` with your actual ingestion pipeline (Google Drive, Dropbox, Git repos, audio transcripts, etc.).\n",
    "* Store the raw artifacts and receipts in GCS/S3 and anchor hashes to Arweave or your preferred provenance layer.\n",
    "* Move the chunking + upsert logic into a scheduled Prefect/Dagster flow.\n",
    "* Replace the example query with your production prompts and add evaluation harnesses (hallucination rate, curator stamp agreement).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}